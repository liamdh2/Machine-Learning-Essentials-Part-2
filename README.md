# Machine Learning Essentials Part II

## Overview
This repository continues my handsâ€‘on machine learning journey, covering a broad spectrum of algorithms and techniquesâ€” from regression and clustering to dimensionality reduction, generative AI, and NLP. Each folder contains Jupyter notebooks that explore these topics through practical examples and real datasets.

---

### ğŸ“ `data/`
Provides the raw datasets used throughout Part II:
- **`enrollment_forecast.csv`**: Historical enrollment figures for timeâ€‘series forecasting practice.  
- **`groceries.csv`**: Market basket transaction data for association rule mining.  
- **`iris.data.csv`**: Classic Iris flower measurements for classification examples.  
- **`mtcars.csv`**: Motor Trend Car Road Tests dataset for regression tutorials.  
- **`titanic-training-data.csv`**: Titanic passenger records for survival prediction exercises.  

---

### ğŸ“ `Regression Models/`
Explores foundational regression techniques:
- **`Linear Regression.ipynb`**  
  Implements simple linear regression and evaluates model fit with RMSE and RÂ².  
- **`Multi Linear Regression.ipynb`**  
  Extends to multiple predictors, demonstrating feature selection and multicollinearity checks.  
- **`Logistic Regression Project.ipynb`**  
  Applies logistic regression to binary classification tasks (e.g., survival prediction).  

---

### ğŸ“ `Clustering Models/`
Demonstrates unsupervised grouping and outlier detection:
- **`K-means Cluster Analysis.ipynb`**  
  Partitions data into k clusters, visualizes centroids, and evaluates inertia.  
- **`Hierarchical Cluster Analysis.ipynb`**  
  Builds dendrograms to show nested cluster relationships using agglomerative methods.  
- **`DBSCAN for Outlier Detection.ipynb`**  
  Uses densityâ€‘based clustering to identify core points and detect anomalies.  

---

### ğŸ“ `Common Machine Learning Models/`
Covers a variety of core supervised learning algorithms:
- **`Instance based learning with KNN.ipynb`**  
  Examines kâ€‘nearest neighbors for classification and regression, tuning k.  
- **`Naive Bayes with Bayesian Statistics.ipynb`**  
  Implements Gaussian and multinomial Naive Bayes classifiers on text and numeric data.  
- **`Neural Networks with perceptrons.ipynb`**  
  Builds a basic singleâ€‘layer perceptron network to learn linear decision boundaries.  
- **`Ensemble methods with random forest.ipynb`**  
  Trains a random forest ensemble, explores feature importance and outâ€‘ofâ€‘bag error.  
- **`Association rules models with Apriori Algo.ipynb`**  
  Discovers frequent itemsets and association rules in transaction data using the Apriori algorithm.  

---

### ğŸ“ `Dimension Reducing Models/`
Introduces techniques to reduce feature space:
- **`PCA_Principal_Component_Analysis.ipynb`**  
  Performs PCA to identify principal components and visualize variance explained.  
- **`Explanatory Factor Analysis.ipynb`**  
  Applies factor analysis to uncover latent factors driving observed variables.  

---

### ğŸ“ `Generative AI/`
Experiments with generative modeling techniques:
- **`Gen AI Model.ipynb`**  
  Explores a simple generative AI pipelineâ€”training and sampling from a model to create synthetic data.  

---

### ğŸ“ `Natural Language Processing/`
Applies basic NLP preprocessing and modeling:
- **`Natural Language Processing.ipynb`**  
  Cleans text data, tokenizes, and demonstrates simple text classification or topic modeling.  
